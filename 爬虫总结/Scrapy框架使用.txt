关于Scrapy的基本原理介绍可以看下面两篇博客：
---------------------------------------------------------------
| https://blog.csdn.net/wickedvalley/article/details/51997360 |
| https://blog.csdn.net/junli_chen/article/details/48210061   |
------------------------------------------------------―――---
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
安装Scrapy：

	1：安装 lxml ：pip install xlml
	 
	2：安装 pyOpenSSL ：pip install pyopenssl

	3：安装 Twisted ：pip install teisted （有可能失败）
	
	4：安装 PyWin32 ：pip install pywin32

	5：安装 Scrapy ：pip install scrapy
		
	若下载失败，则可手动下载安装，下载的网站可使用国内镜像网站，具体可参考另一个文件："下载功能模块的国内网站.txt"

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		            以下都是在命令行中执行

创建Scrapy项目：scrapy startproject 项目名

创建Scrapy爬虫（进入项目中的spiders文件夹下）：scrapy genspider 爬虫名 爬取网站的主机名
（注：爬虫名必须唯一。爬取网站的主机名就是 "域名.com" 例：baidu.com/zhihu.com）

运行Scrapy爬虫：scrapy crawl 爬虫名

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			     Scrapy项目下的各文件介绍

items.py（项）：该文件主要是定义要爬取数据的名字。（例如：小说名，图片地址，url链接....）

		定义格式为：name = scrapy.Field();

――――――――――――――――――――――――――――――――――――――――――――――
middlewares.py（中间件）：该文件主要用于设置访问时使用的Cookies，代理IP，User-Agent等。
		
		第一个类：SpiderMiddleware()。该类的作用暂时不明
		
		第二个类：DownloaderMiddleware()。各方法用法如下：

			process_request()：在发送请求前之前执行该方法（使用代理IP，Cookies，User-Agent，使用Selenium都在该方法中进行）。return 修改后的Request

			process_response()：在把获得的请求发送给引擎之前执行该方法。（修改返回的请求中的一些数据，不常用）。return 修改后的Response
	
			process_exception()：发送请求发生错误时执行该方法。（可在该方法中对出错的请求进行一些操作）。

――――――――――――――――――――――――――――――――――――――――――――――
pipelines.py（管道）：该文件主要用于对 item 携带的数据进行操作。（保存到数据库，下载图片等）
		
		process_item()：该方法必须实现，也是在该方法中对数据进行操作。return item

――――――――――――――――――――――――――――――――――――――――――――――
settings.py（设置）：Scrapy爬虫中的各种配置都在该文件中设置

	一些配置简介：
		ITEM_PIPELINES = {"管道类的路径":优先级（数值越小，优先级越高）}
		
		DOWNLOADER_MIDDLEWARES = {"下载件的路径":"优先级"}

		.....

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			如何下载图片：

	1：可在 settings.py 中配置两个变量：
		IMAGES_STORE = "保存图片的文件夹名"
		IMAGE_URLS_FIELD = "item中保存图片连接的哪一项的名字"
	即可自动将图片下载在同一个文件夹内

	2：自定义图片下载
		
		(1)：自定义一个下载图片的管道类。（继承自 						  scrapy.pipelines.images.ImagesPipeline）

		(2)：若要指定下载图片的链接，可重写 get_media_requests() 方法：
			其中返回一个Request对象

		(3)：若要指定图片下载路径，可重写 file_path() 方法：
			其中返回一个完整的图片路径
	
		  


